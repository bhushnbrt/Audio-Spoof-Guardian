{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca134bd1",
   "metadata": {},
   "source": [
    "1. Extraction using Python script OR Git Bash (faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import tarfile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Set the path to where your .tar files are located\n",
    "base_path = \"C:/Users/Bharat/Videos\"  # UPDATE THIS PATH if needed\n",
    "\n",
    "def extract_tar_files(directory, pattern):\n",
    "    tar_files = glob.glob(os.path.join(directory, pattern))\n",
    "    print(f\"Found {len(tar_files)} files for pattern: {pattern}\")\n",
    "    \n",
    "    for file_path in tar_files:\n",
    "        try:\n",
    "            print(f\"Extracting {file_path}...\")\n",
    "            with tarfile.open(file_path, \"r:\") as tar:\n",
    "                tar.extractall(path=directory)\n",
    "            print(f\"Successfully extracted {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting {file_path}: {e}\")\n",
    "\n",
    "# 1. Protocols (Commented out to skip)\n",
    "# extract_tar_files(base_path, \"ASVspoof5_protocols.tar.gz\")\n",
    "\n",
    "# 2. Extract ONLY flac_T_ac file\n",
    "# Changed pattern from \"flac_T_*.tar\" to specific file \"flac_T_ac.tar\"\n",
    "extract_tar_files(base_path, \"flac_T_ac.tar\")\n",
    "\n",
    "# 3. Dev Data (Commented out to skip)\n",
    "# extract_tar_files(base_path, \"flac_D_*.tar\")\n",
    "\n",
    "print(\"Extraction complete.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e257d1",
   "metadata": {},
   "source": [
    "2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f551ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:04<00:00, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (100, 128, 400, 1)\n",
      "Shape of y: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "FIXED_WIDTH = 400  # Adjust as needed\n",
    "DATASET_FOLDER = \"flac_T\" # Path to your extracted training audio\n",
    "PROTOCOL_FILE = \"ASVspoof5.train.tsv\" # Path to your protocol file\n",
    "\n",
    "def audio_to_spectrogram(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=16000) # ASVspoof5 is 16kHz\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "        # Resize spectrogram to a fixed width\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "        return spec_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset(dataset_path, protocol_path, max_files=1000):\n",
    "    spectrograms, labels = [], []\n",
    "    \n",
    "    # 1. Load the protocol (labels)\n",
    "    # Columns: SPEAKER_ID FLAC_FILE_NAME ... KEY ...\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(protocol_path, sep=' ', names=cols)\n",
    "    \n",
    "    # Limit to max_files for testing\n",
    "    df = df.head(max_files)\n",
    "    \n",
    "    print(f\"Processing {len(df)} files...\")\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        filename = row['FLAC_FILE_NAME'] + \".flac\"\n",
    "        label_str = row['KEY'] # 'spoof' or 'bonafide'\n",
    "        \n",
    "        file_path = os.path.join(dataset_path, filename)\n",
    "        \n",
    "        # Check if file exists before processing\n",
    "        if os.path.exists(file_path):\n",
    "            spec = audio_to_spectrogram(file_path)\n",
    "            if spec is not None:\n",
    "                spectrograms.append(spec)\n",
    "                # 1 for spoof, 0 for bonafide\n",
    "                labels.append(1 if label_str == \"spoof\" else 0)\n",
    "        else:\n",
    "            print(f\"Warning: File not found {file_path}\")\n",
    "\n",
    "    X = np.array(spectrograms)[..., np.newaxis]\n",
    "    y = np.array(labels)\n",
    "    return X, y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure you extract the data first!\n",
    "    if not os.path.exists(DATASET_FOLDER):\n",
    "        print(f\"Error: Folder {DATASET_FOLDER} not found. Please run the extraction script first.\")\n",
    "    else:\n",
    "        X, y = load_dataset(DATASET_FOLDER, PROTOCOL_FILE, max_files=100) # Low number for test\n",
    "        print(f\"Shape of X: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape}\")\n",
    "        np.save(\"X.npy\", X)\n",
    "        np.save(\"y.npy\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79ccfd",
   "metadata": {},
   "source": [
    "3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740beb01",
   "metadata": {},
   "source": [
    "Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65772272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Loading file list...\n",
      "Total Dataset Size: 182357\n",
      "Class Weights (0=Real, 1=Spoof): {0: 4.850222754172485, 1: 0.557468321538297}\n",
      "Training samples: 145885\n",
      "Starting FULL Training (This will take hours)...\n",
      "Epoch 1/5\n",
      "2280/2280 [==============================] - 7997s 4s/step - loss: 1.1086 - accuracy: 0.6249 - val_loss: 0.5507 - val_accuracy: 0.6617\n",
      "Epoch 2/5\n",
      "2280/2280 [==============================] - 6965s 3s/step - loss: 0.5483 - accuracy: 0.6396 - val_loss: 0.5662 - val_accuracy: 0.6617\n",
      "Epoch 3/5\n",
      "2280/2280 [==============================] - 6527s 3s/step - loss: 0.5477 - accuracy: 0.6451 - val_loss: 0.5496 - val_accuracy: 0.6617\n",
      "Epoch 4/5\n",
      "2280/2280 [==============================] - 6137s 3s/step - loss: 0.5478 - accuracy: 0.6503 - val_loss: 0.5644 - val_accuracy: 0.6617\n",
      "Epoch 5/5\n",
      "2280/2280 [==============================] - 6459s 3s/step - loss: 0.5617 - accuracy: 0.6444 - val_loss: 0.5875 - val_accuracy: 0.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf  # Faster audio loading\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight  # <--- NEW IMPORT\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# Double-check these paths match your SSD location\n",
    "DATASET_DIR = \"flac_T\" \n",
    "PROTOCOL_PATH = \"ASVspoof5.train.tsv\"\n",
    "\n",
    "# Batch size 64 is efficient for your 16GB RAM\n",
    "BATCH_SIZE = 64  \n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "class ASVspoofGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, base_dir):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_specs = []\n",
    "        for file_name in batch_x:\n",
    "            file_path = os.path.join(self.base_dir, file_name + \".flac\")\n",
    "            spec = self.process_audio(file_path)\n",
    "            batch_specs.append(spec)\n",
    "\n",
    "        return np.array(batch_specs)[..., np.newaxis], np.array(batch_y)\n",
    "\n",
    "    def process_audio(self, file_path):\n",
    "        if not os.path.exists(file_path):\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "            \n",
    "        try:\n",
    "            # OPTIMIZATION: Use soundfile for speed\n",
    "            y, sr = sf.read(file_path)\n",
    "            \n",
    "            # Safety check for sampling rate\n",
    "            if sr != 16000:\n",
    "                y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "                \n",
    "            spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "            spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "            # Resize to FIXED_WIDTH\n",
    "            if spec_db.shape[1] < FIXED_WIDTH:\n",
    "                pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "                spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            return spec_db\n",
    "        except:\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "\n",
    "# ================= MAIN EXECUTION =================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "    print(\"Loading file list...\")\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "    df['target'] = df['KEY'].apply(lambda x: 1 if x == 'spoof' else 0)\n",
    "    \n",
    "    print(f\"Total Dataset Size: {len(df)}\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df['FLAC_FILE_NAME'].values, \n",
    "        df['target'].values, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # --- CRITICAL FIX: CALCULATE CLASS WEIGHTS ---\n",
    "    # This prevents the model from ignoring 'Real' files\n",
    "    weights = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weights = dict(enumerate(weights))\n",
    "    print(f\"Class Weights (0=Real, 1=Spoof): {class_weights}\")\n",
    "    # ---------------------------------------------\n",
    "\n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    \n",
    "    # Generator Init\n",
    "    train_gen = ASVspoofGenerator(X_train, y_train, BATCH_SIZE, DATASET_DIR)\n",
    "    val_gen = ASVspoofGenerator(X_val, y_val, BATCH_SIZE, DATASET_DIR)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 400, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"Starting FULL Training (This will take hours)...\")\n",
    "    \n",
    "    # FIX APPLIED HERE: use_multiprocessing=False prevents Windows crash\n",
    "    model.fit(\n",
    "        train_gen, \n",
    "        validation_data=val_gen, \n",
    "        epochs=5, \n",
    "        workers=4, \n",
    "        use_multiprocessing=False, \n",
    "        max_queue_size=20,\n",
    "        class_weight=class_weights  # <--- APPLY WEIGHTS HERE\n",
    "    )\n",
    "    \n",
    "    # Save with a NEW name to avoid overwriting your quick test\n",
    "    model.save(\"asvspoof5_full_model.h5\")\n",
    "    print(\"Full Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842c8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Loading full protocol...\n",
      "Original Count -> Real: 18797, Spoof: 163560\n",
      "Balanced Dataset Size: 37594 (50% Real / 50% Spoof)\n",
      "Training on 30075 files (Balanced)\n",
      "Starting BALANCED Training (Fast Mode)...\n",
      "Epoch 1/5\n",
      "470/470 [==============================] - 1812s 4s/step - loss: 2.9566 - accuracy: 0.8228 - val_loss: 0.1905 - val_accuracy: 0.9263\n",
      "Epoch 2/5\n",
      "470/470 [==============================] - 1462s 3s/step - loss: 0.2361 - accuracy: 0.9076 - val_loss: 0.1910 - val_accuracy: 0.9217\n",
      "Epoch 3/5\n",
      "470/470 [==============================] - 1539s 3s/step - loss: 0.1684 - accuracy: 0.9346 - val_loss: 0.1524 - val_accuracy: 0.9415\n",
      "Epoch 4/5\n",
      "470/470 [==============================] - 1598s 3s/step - loss: 0.1563 - accuracy: 0.9380 - val_loss: 0.2497 - val_accuracy: 0.9026\n",
      "Epoch 5/5\n",
      "470/470 [==============================] - 1625s 3s/step - loss: 0.1266 - accuracy: 0.9495 - val_loss: 0.1531 - val_accuracy: 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Model saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "DATASET_DIR = \"flac_T\" \n",
    "PROTOCOL_PATH = \"ASVspoof5.train.tsv\"\n",
    "BATCH_SIZE = 64  \n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "class ASVspoofGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, base_dir):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_specs = []\n",
    "        for file_name in batch_x:\n",
    "            file_path = os.path.join(self.base_dir, file_name + \".flac\")\n",
    "            spec = self.process_audio(file_path)\n",
    "            batch_specs.append(spec)\n",
    "\n",
    "        return np.array(batch_specs)[..., np.newaxis], np.array(batch_y)\n",
    "\n",
    "    def process_audio(self, file_path):\n",
    "        if not os.path.exists(file_path):\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "        try:\n",
    "            y, sr = sf.read(file_path)\n",
    "            if sr != 16000:\n",
    "                y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "            spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "            spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "            if spec_db.shape[1] < FIXED_WIDTH:\n",
    "                pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "                spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            return spec_db\n",
    "        except:\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    \n",
    "    # 1. Load Protocol\n",
    "    print(\"Loading full protocol...\")\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "    df['target'] = df['KEY'].apply(lambda x: 1 if x == 'spoof' else 0)\n",
    "    \n",
    "    # 2. CREATE BALANCED SUBSET (The Fix)\n",
    "    df_real = df[df['target'] == 0]\n",
    "    df_spoof = df[df['target'] == 1]\n",
    "    \n",
    "    print(f\"Original Count -> Real: {len(df_real)}, Spoof: {len(df_spoof)}\")\n",
    "    \n",
    "    # Take all Reals, and match that count with Spoofs\n",
    "    n_samples = len(df_real) \n",
    "    df_spoof_balanced = df_spoof.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    # Combine and Shuffle\n",
    "    df_balanced = pd.concat([df_real, df_spoof_balanced]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Balanced Dataset Size: {len(df_balanced)} (50% Real / 50% Spoof)\")\n",
    "    \n",
    "    # 3. Split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_balanced['FLAC_FILE_NAME'].values, \n",
    "        df_balanced['target'].values, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training on {len(X_train)} files (Balanced)\")\n",
    "\n",
    "    train_gen = ASVspoofGenerator(X_train, y_train, BATCH_SIZE, DATASET_DIR)\n",
    "    val_gen = ASVspoofGenerator(X_val, y_val, BATCH_SIZE, DATASET_DIR)\n",
    "\n",
    "    # 4. Model (Same architecture, cleaner training)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 400, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"Starting BALANCED Training (Fast Mode)...\")\n",
    "    \n",
    "    # Note: No 'class_weights' needed because data is balanced!\n",
    "    model.fit(\n",
    "        train_gen, \n",
    "        validation_data=val_gen, \n",
    "        epochs=5, \n",
    "        workers=4, \n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    model.save(\"asvspoof5_balanced.h5\")\n",
    "    print(\"Balanced Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4760d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Loading full protocol...\n",
      "Original Count -> Real: 18797, Spoof: 163560\n",
      "Balanced Dataset Size: 37594 (50% Real / 50% Spoof)\n",
      "Training on 30075 files (Balanced)\n",
      "Starting NORMALIZED Training...\n",
      "Epoch 1/5\n",
      "470/470 [==============================] - 2397s 5s/step - loss: 1.0169 - accuracy: 0.7034 - val_loss: 0.4157 - val_accuracy: 0.8816\n",
      "Epoch 2/5\n",
      "470/470 [==============================] - 2306s 5s/step - loss: 0.4473 - accuracy: 0.8088 - val_loss: 0.3657 - val_accuracy: 0.8800\n",
      "Epoch 3/5\n",
      "470/470 [==============================] - 2360s 5s/step - loss: 0.3633 - accuracy: 0.8604 - val_loss: 0.5020 - val_accuracy: 0.7385\n",
      "Epoch 4/5\n",
      "470/470 [==============================] - 2368s 5s/step - loss: 0.2973 - accuracy: 0.8954 - val_loss: 0.3102 - val_accuracy: 0.8847\n",
      "Epoch 5/5\n",
      "470/470 [==============================] - 2336s 5s/step - loss: 0.2552 - accuracy: 0.9137 - val_loss: 0.7230 - val_accuracy: 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Model saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "DATASET_DIR = \"flac_T\" \n",
    "PROTOCOL_PATH = \"ASVspoof5.train.tsv\"\n",
    "BATCH_SIZE = 64  \n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "class ASVspoofGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, base_dir):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_specs = []\n",
    "        for file_name in batch_x:\n",
    "            file_path = os.path.join(self.base_dir, file_name + \".flac\")\n",
    "            spec = self.process_audio(file_path)\n",
    "            batch_specs.append(spec)\n",
    "\n",
    "        return np.array(batch_specs)[..., np.newaxis], np.array(batch_y)\n",
    "\n",
    "    def process_audio(self, file_path):\n",
    "        if not os.path.exists(file_path):\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "        try:\n",
    "            y, sr = sf.read(file_path)\n",
    "            if sr != 16000:\n",
    "                y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "                \n",
    "            # Generate Mel Spectrogram\n",
    "            spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "            spec_db = librosa.power_to_db(spec, ref=np.max) # Range: -80 to 0\n",
    "\n",
    "            # Resize\n",
    "            if spec_db.shape[1] < FIXED_WIDTH:\n",
    "                pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "                spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "            # --- NORMALIZATION FIX ---\n",
    "            # Map -80dB...0dB to 0.0...1.0\n",
    "            # This prevents the model from getting saturated\n",
    "            spec_norm = (spec_db + 80.0) / 80.0\n",
    "            return spec_norm\n",
    "            # -------------------------\n",
    "        except:\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    \n",
    "    # 1. Load Protocol\n",
    "    print(\"Loading full protocol...\")\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "    df['target'] = df['KEY'].apply(lambda x: 1 if x == 'spoof' else 0)\n",
    "    \n",
    "    # 2. CREATE BALANCED SUBSET\n",
    "    df_real = df[df['target'] == 0]\n",
    "    df_spoof = df[df['target'] == 1]\n",
    "    \n",
    "    print(f\"Original Count -> Real: {len(df_real)}, Spoof: {len(df_spoof)}\")\n",
    "    \n",
    "    n_samples = len(df_real) \n",
    "    df_spoof_balanced = df_spoof.sample(n=n_samples, random_state=42)\n",
    "    df_balanced = pd.concat([df_real, df_spoof_balanced]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Balanced Dataset Size: {len(df_balanced)} (50% Real / 50% Spoof)\")\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_balanced['FLAC_FILE_NAME'].values, \n",
    "        df_balanced['target'].values, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training on {len(X_train)} files (Balanced)\")\n",
    "\n",
    "    train_gen = ASVspoofGenerator(X_train, y_train, BATCH_SIZE, DATASET_DIR)\n",
    "    val_gen = ASVspoofGenerator(X_val, y_val, BATCH_SIZE, DATASET_DIR)\n",
    "\n",
    "    # 3. PRO MODEL ARCHITECTURE\n",
    "    # Includes BatchNormalization to fix saturation\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Layer 1\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), input_shape=(128, 400, 1)),\n",
    "        tf.keras.layers.BatchNormalization(), # <--- Stabilizes training\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Layer 2\n",
    "        tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "        tf.keras.layers.BatchNormalization(), # <--- Stabilizes training\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Classifier\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"Starting NORMALIZED Training...\")\n",
    "    \n",
    "    model.fit(\n",
    "        train_gen, \n",
    "        validation_data=val_gen, \n",
    "        epochs=5, \n",
    "        workers=4, \n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    model.save(\"asvspoof5_normalized.h5\")\n",
    "    print(\"Normalized Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd40c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: asvspoof5_normalized.h5...\n",
      "âœ… Model loaded successfully!\n",
      "Loading Dev Protocol: ASVspoof5.dev.track_1.tsv...\n",
      "Evaluating on 2000 files from Dev set...\n",
      "Starting predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1902/2000 [05:52<00:19,  5.14it/s]c:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1280\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [06:11<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "FINAL EER: 40.14%\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "MODEL_PATH = \"asvspoof5_normalized.h5\"  # <--- NEW FILE\n",
    "PROTOCOL_PATH = \"ASVspoof5.dev.track_1.tsv\"\n",
    "AUDIO_DIR = \"flac_D\"\n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "def compute_eer(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    return eer * 100\n",
    "\n",
    "def preprocess_for_eval(file_path):\n",
    "    if not os.path.exists(file_path): return None\n",
    "    try:\n",
    "        y, sr = sf.read(file_path)\n",
    "        if sr != 16000: y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        \n",
    "        # SAME PREPROCESSING AS TRAINING\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "        \n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "        # *** CRITICAL NORMALIZATION STEP ***\n",
    "        spec_norm = (spec_db + 80.0) / 80.0\n",
    "        return spec_norm[..., np.newaxis]\n",
    "    except: return None\n",
    "\n",
    "print(f\"Loading model: {MODEL_PATH}...\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "\n",
    "print(f\"Loading Dev Protocol: {PROTOCOL_PATH}...\")\n",
    "cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "        \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "\n",
    "# Test on 1000 random files\n",
    "test_df = df.sample(2000, random_state=42)\n",
    "print(f\"Evaluating on {len(test_df)} files from Dev set...\")\n",
    "\n",
    "y_true = []\n",
    "y_scores = []\n",
    "\n",
    "print(\"Starting predictions...\")\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    file_path = os.path.join(AUDIO_DIR, row['FLAC_FILE_NAME'] + \".flac\")\n",
    "    \n",
    "    spec = preprocess_for_eval(file_path)\n",
    "    if spec is not None:\n",
    "        # Get probability (0.0 to 1.0)\n",
    "        score = model.predict(np.array([spec]), verbose=0)[0][0]\n",
    "        \n",
    "        # KEY: spoof=1, bonafide=0\n",
    "        true_label = 1 if row['KEY'] == 'spoof' else 0\n",
    "        \n",
    "        y_true.append(true_label)\n",
    "        y_scores.append(score)\n",
    "\n",
    "final_eer = compute_eer(y_true, y_scores)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"FINAL EER: {final_eer:.2f}%\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29b7434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: asvspoof5_normalized.h5...\n",
      "âœ… Model loaded successfully!\n",
      "Loading Dev Protocol: ASVspoof5.dev.track_1.tsv...\n",
      "Processing ALL 140950 files from Dev set...\n",
      "Starting predictions (saving to dev_full_scores.txt)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1454/140950 [05:49<9:18:51,  4.16it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFLAC_FILE_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     72\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(AUDIO_DIR, file_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.flac\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_for_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([spec]), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m, in \u001b[0;36mpreprocess_for_eval\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_for_eval\u001b[39m(file_path):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m         y, sr \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mread(file_path)\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "MODEL_PATH = \"asvspoof5_normalized.h5\"\n",
    "PROTOCOL_PATH = \"ASVspoof5.dev.track_1.tsv\"  # Using DEV protocol\n",
    "AUDIO_DIR = \"flac_D\"                         # Using DEV audio folder\n",
    "OUTPUT_FILE = \"dev_full_scores.txt\"\n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "def preprocess_for_eval(file_path):\n",
    "    if not os.path.exists(file_path): return None\n",
    "    try:\n",
    "        y, sr = sf.read(file_path)\n",
    "        if sr != 16000: y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        \n",
    "        # Standard Mel Spectrogram\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "        \n",
    "        # Padding / Trimming\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "        # Normalization (Crucial)\n",
    "        spec_norm = (spec_db + 80.0) / 80.0\n",
    "        return spec_norm[..., np.newaxis]\n",
    "    except: return None\n",
    "\n",
    "# 1. Load Model\n",
    "print(f\"Loading model: {MODEL_PATH}...\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"ðŸš¨ ERROR: Model file '{MODEL_PATH}' not found.\")\n",
    "    exit()\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "\n",
    "# 2. Load Protocol\n",
    "print(f\"Loading Dev Protocol: {PROTOCOL_PATH}...\")\n",
    "try:\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "except:\n",
    "    print(\"Warning: Standard column headers failed. Reading as raw list...\")\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', header=None)\n",
    "    df.rename(columns={1: 'FLAC_FILE_NAME'}, inplace=True)\n",
    "\n",
    "print(f\"Processing ALL {len(df)} files from Dev set...\")\n",
    "\n",
    "# 3. Processing Loop\n",
    "y_true = []\n",
    "y_scores = []\n",
    "has_labels = 'KEY' in df.columns # Dev set usually has labels\n",
    "\n",
    "print(f\"Starting predictions (saving to {OUTPUT_FILE})...\")\n",
    "\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    # iterrows is slow, but acceptable for inference script\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        file_name = str(row['FLAC_FILE_NAME'])\n",
    "        file_path = os.path.join(AUDIO_DIR, file_name + \".flac\")\n",
    "        \n",
    "        spec = preprocess_for_eval(file_path)\n",
    "        \n",
    "        if spec is not None:\n",
    "            score = model.predict(np.array([spec]), verbose=0)[0][0]\n",
    "            f.write(f\"{file_name} {score}\\n\")\n",
    "            \n",
    "            if has_labels:\n",
    "                y_scores.append(score)\n",
    "                # 'spoof' = 1, 'bonafide' = 0\n",
    "                true_label = 1 if row['KEY'] == 'spoof' else 0\n",
    "                y_true.append(true_label)\n",
    "        else:\n",
    "            # If file missing or corrupt, write 0.0\n",
    "            f.write(f\"{file_name} 0.0\\n\")\n",
    "\n",
    "print(f\"âœ… Full Dev evaluation saved to {OUTPUT_FILE}\")\n",
    "\n",
    "# 4. Calculate EER\n",
    "if has_labels and len(y_scores) > 0:\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))] * 100\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "    print(f\"FINAL FULL DEV SET EER: {eer:.2f}%\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0184cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Loading full protocol...\n",
      "Training on 30075 files (Balanced)\n",
      "Starting Training (Saving SEPARATE files for each epoch)...\n",
      "Epoch 1/8\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8869\n",
      "Epoch 1: saving model to asvspoof5_epoch_01.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1861s 4s/step - loss: 0.3056 - accuracy: 0.8869 - val_loss: 1.4357 - val_accuracy: 0.5006\n",
      "Epoch 2/8\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.9451\n",
      "Epoch 2: saving model to asvspoof5_epoch_02.h5\n",
      "470/470 [==============================] - 1929s 4s/step - loss: 0.1408 - accuracy: 0.9451 - val_loss: 0.0833 - val_accuracy: 0.9634\n",
      "Epoch 3/8\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9543\n",
      "Epoch 3: saving model to asvspoof5_epoch_03.h5\n",
      "470/470 [==============================] - 2469s 5s/step - loss: 0.1136 - accuracy: 0.9543 - val_loss: 0.0549 - val_accuracy: 0.9770\n",
      "Epoch 4/8\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9650\n",
      "Epoch 4: saving model to asvspoof5_epoch_04.h5\n",
      "470/470 [==============================] - 2378s 5s/step - loss: 0.0886 - accuracy: 0.9650 - val_loss: 0.0445 - val_accuracy: 0.9832\n",
      "Epoch 5/8\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9708\n",
      "Epoch 5: saving model to asvspoof5_epoch_05.h5\n",
      "470/470 [==============================] - 2180s 5s/step - loss: 0.0735 - accuracy: 0.9708 - val_loss: 0.0482 - val_accuracy: 0.9820\n",
      "Epoch 6/8\n",
      " 24/470 [>.............................] - ETA: 36:06 - loss: 0.0698 - accuracy: 0.9688"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 126\u001b[0m\n\u001b[0;32m    117\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masvspoof5_epoch_\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    119\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    120\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Save EVERY file\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Training (Saving SEPARATE files for each epoch)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 126\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Complete. Check your folder for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masvspoof5_epoch_XX.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Bharat\\anaconda3\\envs\\adf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "DATASET_DIR = \"flac_T\" \n",
    "PROTOCOL_PATH = \"ASVspoof5.train.tsv\"\n",
    "BATCH_SIZE = 64  \n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "class ASVspoofGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, base_dir):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_specs = []\n",
    "        for file_name in batch_x:\n",
    "            file_path = os.path.join(self.base_dir, file_name + \".flac\")\n",
    "            spec = self.process_audio(file_path)\n",
    "            batch_specs.append(spec)\n",
    "\n",
    "        return np.array(batch_specs)[..., np.newaxis], np.array(batch_y)\n",
    "\n",
    "    def process_audio(self, file_path):\n",
    "        if not os.path.exists(file_path):\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "        try:\n",
    "            y, sr = sf.read(file_path)\n",
    "            if sr != 16000:\n",
    "                y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "            \n",
    "            # --- NORMALIZATION LOGIC ---\n",
    "            spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "            spec_db = librosa.power_to_db(spec, ref=np.max) \n",
    "            \n",
    "            if spec_db.shape[1] < FIXED_WIDTH:\n",
    "                pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "                spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "            # Map -80dB...0dB to 0.0...1.0\n",
    "            spec_norm = (spec_db + 80.0) / 80.0\n",
    "            return spec_norm\n",
    "            # ---------------------------\n",
    "        except:\n",
    "            return np.zeros((128, FIXED_WIDTH))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    \n",
    "    # 1. Load Protocol\n",
    "    print(\"Loading full protocol...\")\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "    df['target'] = df['KEY'].apply(lambda x: 1 if x == 'spoof' else 0)\n",
    "    \n",
    "    # 2. CREATE BALANCED SUBSET\n",
    "    df_real = df[df['target'] == 0]\n",
    "    df_spoof = df[df['target'] == 1]\n",
    "    \n",
    "    n_samples = len(df_real) \n",
    "    df_spoof_balanced = df_spoof.sample(n=n_samples, random_state=42)\n",
    "    df_balanced = pd.concat([df_real, df_spoof_balanced]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_balanced['FLAC_FILE_NAME'].values, \n",
    "        df_balanced['target'].values, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Training on {len(X_train)} files (Balanced)\")\n",
    "\n",
    "    train_gen = ASVspoofGenerator(X_train, y_train, BATCH_SIZE, DATASET_DIR)\n",
    "    val_gen = ASVspoofGenerator(X_val, y_val, BATCH_SIZE, DATASET_DIR)\n",
    "\n",
    "    # 3. MODEL (With Batch Norm)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), input_shape=(128, 400, 1)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 4. CALLBACK: SAVE EVERY EPOCH\n",
    "    # This creates: asvspoof5_epoch_01.h5, asvspoof5_epoch_02.h5, etc.\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"asvspoof5_epoch_{epoch:02d}.h5\", \n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=False, # Save EVERY file\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"Starting Training (Saving SEPARATE files for each epoch)...\")\n",
    "    \n",
    "    model.fit(\n",
    "        train_gen, \n",
    "        validation_data=val_gen, \n",
    "        epochs=8, \n",
    "        callbacks=[checkpoint],\n",
    "        workers=4, \n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    print(\"Training Complete. Check your folder for 'asvspoof5_epoch_XX.h5' files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd00c6",
   "metadata": {},
   "source": [
    "4. Evaluation on Development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846ca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: asvspoof5_epoch_04.h5...\n",
      "âœ… Model loaded successfully!\n",
      "Loading Protocol: ASVspoof5.dev.track_1.tsv...\n",
      "Evaluating on 5000 random files...\n",
      "Starting predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:01<00:00, 3803.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scores saved to dev_best_scores.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# 1. THE WINNING MODEL (Check if Epoch 3 beat this!)\n",
    "MODEL_PATH = \"asvspoof5_epoch_04.h5\" \n",
    "\n",
    "# 2. DATASET PATHS (Dev Set)\n",
    "PROTOCOL_PATH = \"ASVspoof5.dev.track_1.tsv\"\n",
    "AUDIO_DIR = \"flac_D\"\n",
    "\n",
    "# 3. OUTPUT\n",
    "OUTPUT_FILE = \"dev_best_scores.txt\"\n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "def preprocess_for_eval(file_path):\n",
    "    if not os.path.exists(file_path): return None\n",
    "    try:\n",
    "        y, sr = sf.read(file_path)\n",
    "        if sr != 16000: y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        \n",
    "        # --- FIX FOR SHORT AUDIO ---\n",
    "        # Pad with silence if shorter than 0.12s (2048 samples)\n",
    "        if len(y) < 2048:\n",
    "            padding = 2048 - len(y)\n",
    "            y = np.pad(y, (0, padding), mode='constant')\n",
    "        # ---------------------------\n",
    "\n",
    "        # Mel Spectrogram\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "        \n",
    "        # Resize to FIXED_WIDTH\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "        # *** NORMALIZATION (0.0 to 1.0) ***\n",
    "        # This matches your training exactly.\n",
    "        spec_norm = (spec_db + 80.0) / 80.0\n",
    "        \n",
    "        return spec_norm[..., np.newaxis]\n",
    "    except: return None\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "print(f\"Loading model: {MODEL_PATH}...\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"ðŸš¨ ERROR: Model file '{MODEL_PATH}' not found. Did you mean epoch_03?\")\n",
    "    exit()\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "\n",
    "print(f\"Loading Protocol: {PROTOCOL_PATH}...\")\n",
    "try:\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "except:\n",
    "    print(\"Warning: Standard headers failed. Reading as raw list...\")\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', header=None)\n",
    "    df.rename(columns={1: 'FLAC_FILE_NAME'}, inplace=True)\n",
    "\n",
    "# OPTIONAL: Test on smaller subset first to confirm low EER\n",
    "# Comment this out to run the FULL set\n",
    "test_df = df.sample(5000, random_state=42)\n",
    "print(f\"Evaluating on {len(test_df)} random files...\")\n",
    "\n",
    "y_true = []\n",
    "y_scores = []\n",
    "has_labels = 'KEY' in df.columns\n",
    "\n",
    "print(f\"Starting predictions...\")\n",
    "\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "        file_name = str(row['FLAC_FILE_NAME'])\n",
    "        file_path = os.path.join(AUDIO_DIR, file_name + \".flac\")\n",
    "        \n",
    "        spec = preprocess_for_eval(file_path)\n",
    "        \n",
    "        if spec is not None:\n",
    "            # Predict\n",
    "            score = model.predict(np.array([spec]), verbose=0)[0][0]\n",
    "            f.write(f\"{file_name} {score}\\n\")\n",
    "            \n",
    "            if has_labels:\n",
    "                y_scores.append(score)\n",
    "                # 1=Spoof, 0=Bonafide\n",
    "                true_label = 1 if row['KEY'] == 'spoof' else 0\n",
    "                y_true.append(true_label)\n",
    "        else:\n",
    "            f.write(f\"{file_name} 0.0\\n\")\n",
    "\n",
    "print(f\"âœ… Scores saved to {OUTPUT_FILE}\")\n",
    "\n",
    "if has_labels and len(y_scores) > 0:\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))] * 100\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"ðŸŒŸ FINAL EER (Epoch 02): {eer:.2f}% ðŸŒŸ\")\n",
    "    print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fdeedfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: asvspoof5_epoch_04.h5...\n",
      "âœ… Model loaded!\n",
      "Loading Protocol...\n",
      "ðŸš€ Processing 140950 files in batches of 256...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140950/140950 [1:32:09<00:00, 25.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation complete. Saved to final_dev_full_scores_fast.txt\n",
      "\n",
      "==================================================\n",
      "ðŸ† OFFICIAL FINAL EER (Epoch 04): 21.8389% ðŸ†\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "MODEL_PATH = \"asvspoof5_epoch_04.h5\" \n",
    "PROTOCOL_PATH = \"ASVspoof5.dev.track_1.tsv\"\n",
    "AUDIO_DIR = \"flac_D\"\n",
    "OUTPUT_FILE = \"final_dev_full_scores_fast.txt\"\n",
    "FIXED_WIDTH = 400\n",
    "BATCH_SIZE = 256  # Process 64 files at once\n",
    "# =================================================\n",
    "\n",
    "def preprocess_for_eval(file_path):\n",
    "    if not os.path.exists(file_path): return None\n",
    "    try:\n",
    "        y, sr = sf.read(file_path)\n",
    "        if sr != 16000: y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        \n",
    "        # Pad short audio\n",
    "        if len(y) < 2048:\n",
    "            padding = 2048 - len(y)\n",
    "            y = np.pad(y, (0, padding), mode='constant')\n",
    "\n",
    "        # Mel Spectrogram\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "        \n",
    "        # Resize\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "        # Normalize\n",
    "        spec_norm = (spec_db + 80.0) / 80.0\n",
    "        return spec_norm[..., np.newaxis]\n",
    "    except: return None\n",
    "\n",
    "# Load Model\n",
    "print(f\"Loading Model: {MODEL_PATH}...\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"âœ… Model loaded!\")\n",
    "\n",
    "# Load Protocol\n",
    "print(\"Loading Protocol...\")\n",
    "try:\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "except:\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', header=None)\n",
    "    df.rename(columns={1: 'FLAC_FILE_NAME'}, inplace=True)\n",
    "\n",
    "print(f\"ðŸš€ Processing {len(df)} files in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "# Data containers\n",
    "filenames = []\n",
    "specs = []\n",
    "y_true = []\n",
    "all_scores = {} # Store results to write later\n",
    "has_labels = 'KEY' in df.columns\n",
    "\n",
    "# Open file for writing results incrementally\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        file_name = str(row['FLAC_FILE_NAME'])\n",
    "        file_path = os.path.join(AUDIO_DIR, file_name + \".flac\")\n",
    "        \n",
    "        # 1. Preprocess\n",
    "        s = preprocess_for_eval(file_path)\n",
    "        \n",
    "        if s is not None:\n",
    "            specs.append(s)\n",
    "            filenames.append(file_name)\n",
    "            if has_labels:\n",
    "                label = 1 if row['KEY'] == 'spoof' else 0\n",
    "                y_true.append(label)\n",
    "        else:\n",
    "            # Handle error immediately\n",
    "            f.write(f\"{file_name} 0.0\\n\")\n",
    "\n",
    "        # 2. When batch is full, PREDICT\n",
    "        if len(specs) >= BATCH_SIZE:\n",
    "            batch_preds = model.predict_on_batch(np.array(specs))\n",
    "            \n",
    "            # Write batch to file\n",
    "            for i, fname in enumerate(filenames):\n",
    "                score = batch_preds[i][0]\n",
    "                f.write(f\"{fname} {score}\\n\")\n",
    "                all_scores[fname] = score # Keep for EER calc\n",
    "            \n",
    "            # Clear buffer\n",
    "            specs = []\n",
    "            filenames = []\n",
    "\n",
    "    # 3. Process remaining files (leftovers)\n",
    "    if len(specs) > 0:\n",
    "        batch_preds = model.predict_on_batch(np.array(specs))\n",
    "        for i, fname in enumerate(filenames):\n",
    "            score = batch_preds[i][0]\n",
    "            f.write(f\"{fname} {score}\\n\")\n",
    "            all_scores[fname] = score\n",
    "\n",
    "print(f\"âœ… Evaluation complete. Saved to {OUTPUT_FILE}\")\n",
    "\n",
    "# Calculate EER\n",
    "if has_labels and len(y_true) > 0:\n",
    "    # Re-align scores with labels (since we skipped errors)\n",
    "    # This is a quick approximation using the collected lists\n",
    "    # Ideally, we should match exact indices, but for this dataset, errors are rare.\n",
    "    valid_scores = list(all_scores.values())\n",
    "    \n",
    "    # Ensure lengths match (truncate labels if errors occurred)\n",
    "    if len(valid_scores) <= len(y_true):\n",
    "        # We only kept labels for successful loads\n",
    "        # This aligns y_true with valid_scores\n",
    "        pass \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true[:len(valid_scores)], valid_scores, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))] * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ðŸ† OFFICIAL FINAL EER (Epoch 04): {eer:.4f}% ðŸ†\")\n",
    "    print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75ab859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      " ðŸ•µï¸  DEEPFAKE DETECTOR - LIVE TEST \n",
      "==================================================\n",
      "Loading AI Brain...\n",
      "Processing: flac_D/D_0002136877.flac...\n",
      "Analyzing audio patterns...\n",
      "\n",
      "------------------------------\n",
      "RAW SCORE: 0.0000\n",
      "------------------------------\n",
      "âœ… RESULT: REAL HUMAN VOICE\n",
      "ðŸ’ª Confidence: 100.00%\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# 1. YOUR TRAINED MODEL\n",
    "MODEL_PATH = \"asvspoof5_epoch_04.h5\"\n",
    "\n",
    "# 2. THE FILE TO TEST (Change this filename!)\n",
    "# You can use .wav, .mp3, .flac, etc.\n",
    "# TEST_FILE = \"bharat.wav\"  # <--- CHANGE THIS\n",
    "TEST_FILE = \"flac_D/D_0002136877.flac\" # Point to a real Dev file\n",
    "#TEST_FILE = \"flac_D/D_0000128101.flac\" # Point to a fake Dev file\n",
    "# =================================================\n",
    "\n",
    "# Constants (Must match training)\n",
    "FIXED_WIDTH = 400  # ~4 seconds of audio\n",
    "\n",
    "def preprocess_audio(file_path):\n",
    "    print(f\"Processing: {file_path}...\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âŒ ERROR: File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Load audio (automatically resamples to 16kHz)\n",
    "        y, sr = librosa.load(file_path, sr=16000)\n",
    "        \n",
    "        # Trim silence from beginning and end (optional, but helps)\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "\n",
    "        # Fix Length: Pad if too short\n",
    "        if len(y) < 2048:\n",
    "            padding = 2048 - len(y)\n",
    "            y = np.pad(y, (0, padding), mode='constant')\n",
    "\n",
    "        # Generate Mel Spectrogram\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "        \n",
    "        # Fit to Model Input Shape (Truncate or Pad to FIXED_WIDTH)\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            # Note: We only test the FIRST 4 seconds\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "        # Normalize (Crucial!)\n",
    "        spec_norm = (spec_db + 80.0) / 80.0\n",
    "        \n",
    "        # Add batch and channel dimensions: (1, 128, 400, 1)\n",
    "        return spec_norm[np.newaxis, ..., np.newaxis]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "print(\"=\"*50)\n",
    "print(\" ðŸ•µï¸  DEEPFAKE DETECTOR - LIVE TEST \")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Load Model\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"ðŸš¨ Model file not found! Check the name.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"Loading AI Brain...\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# 2. Process Audio\n",
    "input_tensor = preprocess_audio(TEST_FILE)\n",
    "\n",
    "if input_tensor is not None:\n",
    "    # 3. Predict\n",
    "    print(\"Analyzing audio patterns...\")\n",
    "    prediction = model.predict(input_tensor, verbose=0)[0][0]\n",
    "    \n",
    "    # 4. Interpret Result\n",
    "    # In our training: 0 = Bonafide (Real), 1 = Spoof (Fake)\n",
    "    \n",
    "    score_percent = prediction * 100\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*30)\n",
    "    print(f\"RAW SCORE: {prediction:.4f}\")\n",
    "    print(\"-\"*30)\n",
    "\n",
    "    if prediction < 0.50:\n",
    "        confidence = (1 - prediction) * 100\n",
    "        print(f\"âœ… RESULT: REAL HUMAN VOICE\")\n",
    "        print(f\"ðŸ’ª Confidence: {confidence:.2f}%\")\n",
    "    else:\n",
    "        confidence = prediction * 100\n",
    "        print(f\"âš ï¸ RESULT: ARTIFICIAL / DEEPFAKE\")\n",
    "        print(f\"ðŸš¨ Confidence: {confidence:.2f}%\")\n",
    "    print(\"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343a45f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ•µï¸  Starting Forensic Analysis...\n",
      "Loading Truth from ASVspoof5.dev.track_1.tsv...\n",
      "Loading Scores from final_dev_full_scores_fast.txt...\n",
      "Merging data...\n",
      "Successfully matched 140950 files.\n",
      "\n",
      "============================================================\n",
      "ðŸš¨ TOP 5 FALSE ALARMS (Real Humans flagged as Deepfakes)\n",
      "These files are likely noisy, short, or have weird microphones.\n",
      "============================================================\n",
      "File: D_0001602028.flac  |  Model Confidence: 100.00% Fake\n",
      "File: D_0001170373.flac  |  Model Confidence: 100.00% Fake\n",
      "File: D_0000114661.flac  |  Model Confidence: 100.00% Fake\n",
      "File: D_0002759149.flac  |  Model Confidence: 100.00% Fake\n",
      "File: D_0000128101.flac  |  Model Confidence: 100.00% Fake\n",
      "\n",
      "============================================================\n",
      "âš ï¸ TOP 5 MISSED ATTACKS (Deepfakes that tricked the AI)\n",
      "These are the 'Super-Deepfakes' your model cannot detect.\n",
      "============================================================\n",
      "File: D_0002534512.flac  |  Model Confidence: 100.00% Real\n",
      "File: D_0000437431.flac  |  Model Confidence: 100.00% Real\n",
      "File: D_0001767508.flac  |  Model Confidence: 100.00% Real\n",
      "File: D_0001546420.flac  |  Model Confidence: 100.00% Real\n",
      "File: D_0002136877.flac  |  Model Confidence: 100.00% Real\n",
      "\n",
      "Done. Copy these filenames and listen to them in your folder!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "PROTOCOL_PATH = \"ASVspoof5.dev.track_1.tsv\"\n",
    "SCORES_FILE = \"final_dev_full_scores_fast.txt\"\n",
    "# =================================================\n",
    "\n",
    "print(\"ðŸ•µï¸  Starting Forensic Analysis...\")\n",
    "\n",
    "# 1. Load the Truth (Protocol)\n",
    "print(f\"Loading Truth from {PROTOCOL_PATH}...\")\n",
    "try:\n",
    "    # Try reading with headers\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df_truth = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "except:\n",
    "    # Fallback for no headers\n",
    "    df_truth = pd.read_csv(PROTOCOL_PATH, sep=' ', header=None)\n",
    "    df_truth.rename(columns={1: 'FLAC_FILE_NAME', 8: 'KEY'}, inplace=True)\n",
    "\n",
    "# Keep only what we need: Filename and Key (bonafide/spoof)\n",
    "df_truth = df_truth[['FLAC_FILE_NAME', 'KEY']]\n",
    "df_truth['FLAC_FILE_NAME'] = df_truth['FLAC_FILE_NAME'].astype(str)\n",
    "\n",
    "# 2. Load the Predictions (Scores)\n",
    "print(f\"Loading Scores from {SCORES_FILE}...\")\n",
    "# The scores file is \"filename score\"\n",
    "df_scores = pd.read_csv(SCORES_FILE, sep=' ', names=['FLAC_FILE_NAME', 'SCORE'])\n",
    "df_scores['FLAC_FILE_NAME'] = df_scores['FLAC_FILE_NAME'].astype(str)\n",
    "\n",
    "# 3. Merge them\n",
    "print(\"Merging data...\")\n",
    "df = pd.merge(df_truth, df_scores, on='FLAC_FILE_NAME')\n",
    "\n",
    "print(f\"Successfully matched {len(df)} files.\")\n",
    "\n",
    "# ================= ANALYSIS =================\n",
    "\n",
    "# --- CASE 1: FALSE POSITIVES (False Alarms) ---\n",
    "# Truth = 'bonafide' (Real), but Score is HIGH (Model thinks Fake)\n",
    "false_positives = df[df['KEY'] == 'bonafide'].copy()\n",
    "# Sort by score descending (Highest confidence fakes)\n",
    "worst_fp = false_positives.sort_values(by='SCORE', ascending=False).head(5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš¨ TOP 5 FALSE ALARMS (Real Humans flagged as Deepfakes)\")\n",
    "print(\"These files are likely noisy, short, or have weird microphones.\")\n",
    "print(\"=\"*60)\n",
    "for _, row in worst_fp.iterrows():\n",
    "    print(f\"File: {row['FLAC_FILE_NAME']}.flac  |  Model Confidence: {row['SCORE']*100:.2f}% Fake\")\n",
    "\n",
    "# --- CASE 2: FALSE NEGATIVES (Missed Attacks) ---\n",
    "# Truth = 'spoof' (Fake), but Score is LOW (Model thinks Real)\n",
    "false_negatives = df[df['KEY'] == 'spoof'].copy()\n",
    "# Sort by score ascending (Lowest confidence fakes -> Model thought they were very Real)\n",
    "worst_fn = false_negatives.sort_values(by='SCORE', ascending=True).head(5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âš ï¸ TOP 5 MISSED ATTACKS (Deepfakes that tricked the AI)\")\n",
    "print(\"These are the 'Super-Deepfakes' your model cannot detect.\")\n",
    "print(\"=\"*60)\n",
    "for _, row in worst_fn.iterrows():\n",
    "    print(f\"File: {row['FLAC_FILE_NAME']}.flac  |  Model Confidence: {(1-row['SCORE'])*100:.2f}% Real\")\n",
    "\n",
    "print(\"\\nDone. Copy these filenames and listen to them in your folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6b5c8",
   "metadata": {},
   "source": [
    "5. Evaluate on Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# 1. THE WINNING MODEL (Check if Epoch 3 beat this!)\n",
    "MODEL_PATH = \"asvspoof5_epoch_04.h5\" \n",
    "\n",
    "# 2. DATASET PATHS (Dev Set)\n",
    "PROTOCOL_PATH = \"ASVspoof5.eval.track_1.tsv\"\n",
    "AUDIO_DIR = \"flac_E_eval\"\n",
    "\n",
    "# 3. OUTPUT\n",
    "OUTPUT_FILE = \"dev_best_scores.txt\"\n",
    "FIXED_WIDTH = 400\n",
    "# =================================================\n",
    "\n",
    "def preprocess_for_eval(file_path):\n",
    "    if not os.path.exists(file_path): return None\n",
    "    try:\n",
    "        y, sr = sf.read(file_path)\n",
    "        if sr != 16000: y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "        \n",
    "        # --- FIX FOR SHORT AUDIO ---\n",
    "        # Pad with silence if shorter than 0.12s (2048 samples)\n",
    "        if len(y) < 2048:\n",
    "            padding = 2048 - len(y)\n",
    "            y = np.pad(y, (0, padding), mode='constant')\n",
    "        # ---------------------------\n",
    "\n",
    "        # Mel Spectrogram\n",
    "        spec = librosa.feature.melspectrogram(y=y, sr=16000, n_mels=128)\n",
    "        spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "        \n",
    "        # Resize to FIXED_WIDTH\n",
    "        if spec_db.shape[1] < FIXED_WIDTH:\n",
    "            pad_width = FIXED_WIDTH - spec_db.shape[1]\n",
    "            spec_db = np.pad(spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            spec_db = spec_db[:, :FIXED_WIDTH]\n",
    "            \n",
    "        # *** NORMALIZATION (0.0 to 1.0) ***\n",
    "        # This matches your training exactly.\n",
    "        spec_norm = (spec_db + 80.0) / 80.0\n",
    "        \n",
    "        return spec_norm[..., np.newaxis]\n",
    "    except: return None\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "print(f\"Loading model: {MODEL_PATH}...\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"ðŸš¨ ERROR: Model file '{MODEL_PATH}' not found. Did you mean epoch_03?\")\n",
    "    exit()\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "\n",
    "print(f\"Loading Protocol: {PROTOCOL_PATH}...\")\n",
    "try:\n",
    "    cols = [\"SPEAKER_ID\", \"FLAC_FILE_NAME\", \"SPEAKER_GENDER\", \"CODEC\", \"CODEC_Q\", \n",
    "            \"CODEC_SEED\", \"ATTACK_TAG\", \"ATTACK_LABEL\", \"KEY\", \"TMP\"]\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', names=cols)\n",
    "except:\n",
    "    print(\"Warning: Standard headers failed. Reading as raw list...\")\n",
    "    df = pd.read_csv(PROTOCOL_PATH, sep=' ', header=None)\n",
    "    df.rename(columns={1: 'FLAC_FILE_NAME'}, inplace=True)\n",
    "\n",
    "# OPTIONAL: Test on smaller subset first to confirm low EER\n",
    "# Comment this out to run the FULL set\n",
    "test_df = df.sample(5000, random_state=42)\n",
    "print(f\"Evaluating on {len(test_df)} random files...\")\n",
    "\n",
    "y_true = []\n",
    "y_scores = []\n",
    "has_labels = 'KEY' in df.columns\n",
    "\n",
    "print(f\"Starting predictions...\")\n",
    "\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "        file_name = str(row['FLAC_FILE_NAME'])\n",
    "        file_path = os.path.join(AUDIO_DIR, file_name + \".flac\")\n",
    "        \n",
    "        spec = preprocess_for_eval(file_path)\n",
    "        \n",
    "        if spec is not None:\n",
    "            # Predict\n",
    "            score = model.predict(np.array([spec]), verbose=0)[0][0]\n",
    "            f.write(f\"{file_name} {score}\\n\")\n",
    "            \n",
    "            if has_labels:\n",
    "                y_scores.append(score)\n",
    "                # 1=Spoof, 0=Bonafide\n",
    "                true_label = 1 if row['KEY'] == 'spoof' else 0\n",
    "                y_true.append(true_label)\n",
    "        else:\n",
    "            f.write(f\"{file_name} 0.0\\n\")\n",
    "\n",
    "print(f\"âœ… Scores saved to {OUTPUT_FILE}\")\n",
    "\n",
    "if has_labels and len(y_scores) > 0:\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))] * 100\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"ðŸŒŸ FINAL EER (Epoch 02): {eer:.2f}% ðŸŒŸ\")\n",
    "    print(\"=\"*40 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
